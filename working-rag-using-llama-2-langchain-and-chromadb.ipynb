{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10265592,"sourceType":"datasetVersion","datasetId":6350897},{"sourceId":4298,"sourceType":"modelInstanceVersion","modelInstanceId":3093,"modelId":735}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n## Objective\n\nUse Llama 2.0, Langchain and ChromaDB to create a Retrieval Augmented Generation (RAG) system. This will allow us to ask questions about our documents (that were not included in the training data), without fine-tunning the Large Language Model (LLM).\nWhen using RAG, if you are given a question, you first do a retrieval step to fetch any relevant documents from a special database, a vector database where these documents were indexed. \n\n## Definitions\n\n* LLM - Large Language Model  \n* Llama 2.0 - LLM from Meta \n* Langchain - a framework designed to simplify the creation of applications using LLMs\n* Vector database - a database that organizes data through high-dimmensional vectors  \n* ChromaDB - vector database  \n* RAG - Retrieval Augmented Generation (see below more details about RAGs)\n\n## Model details\n\n* **Model**: Llama 2  \n* **Variation**: 7b-chat-hf  (7b: 7B dimm. hf: HuggingFace build)\n* **Version**: V1  \n* **Framework**: PyTorch  \n\nLlaMA 2 model is pretrained and fine-tuned with 2 Trillion tokens and 7 to 70 Billion parameters which makes it one of the powerful open source models. It is a highly improvement over LlaMA 1 model.\n\n\n## What is a Retrieval Augmented Generation (RAG) system?\n\nLarge Language Models (LLMs) has proven their ability to understand context and provide accurate answers to various NLP tasks, including summarization, Q&A, when prompted. While being able to provide very good answers to questions about information that they were trained with, they tend to hallucinate when the topic is about information that they do \"not know\", i.e. was not included in their training data. Retrieval Augmented Generation combines external resources with LLMs. The main two components of a RAG are therefore a retriever and a generator.  \n \nThe retriever part can be described as a system that is able to encode our data so that can be easily retrieved the relevant parts of it upon queriying it. The encoding is done using text embeddings, i.e. a model trained to create a vector representation of the information. The best option for implementing a retriever is a vector database. As vector database, there are multiple options, both open source or commercial products. Few examples are ChromaDB, Mevius, FAISS, Pinecone, Weaviate. Our option in this Notebook will be a local instance of ChromaDB (persistent).\n\nFor the generator part, the obvious option is a LLM. In this Notebook we will use a quantized LLaMA v2 model, from the Kaggle Models collection.  \n\nThe orchestration of the retriever and generator will be done using Langchain. A specialized function from Langchain allows us to create the receiver-generator in one line of code.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"# Installations, imports, utils","metadata":{}},{"cell_type":"code","source":"!pip install transformers==4.33.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T01:16:15.223580Z","iopub.execute_input":"2024-12-22T01:16:15.223948Z","iopub.status.idle":"2024-12-22T01:16:23.620615Z","shell.execute_reply.started":"2024-12-22T01:16:15.223917Z","shell.execute_reply":"2024-12-22T01:16:23.619304Z"}},"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nRequirement already satisfied: transformers==4.33.0 in /opt/conda/lib/python3.10/site-packages (4.33.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (0.16.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (0.3.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (4.66.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.33.0) (2023.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.33.0) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.33.0) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.33.0) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.33.0) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.33.0) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.33.0) (2023.7.22)\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"!pip install accelerate==0.22.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T01:16:23.622803Z","iopub.execute_input":"2024-12-22T01:16:23.623114Z","iopub.status.idle":"2024-12-22T01:16:32.313058Z","shell.execute_reply.started":"2024-12-22T01:16:23.623086Z","shell.execute_reply":"2024-12-22T01:16:32.312139Z"}},"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nRequirement already satisfied: accelerate==0.22.0 in /opt/conda/lib/python3.10/site-packages (0.22.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.22.0) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.22.0) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.22.0) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate==0.22.0) (6.0)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.22.0) (2.0.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate==0.22.0) (3.0.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.22.0) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.22.0) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.22.0) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.22.0) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.22.0) (3.1.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.22.0) (11.7.99)\nRequirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.22.0) (11.7.99)\nRequirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.22.0) (11.7.101)\nRequirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.22.0) (8.5.0.96)\nRequirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.22.0) (11.10.3.66)\nRequirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.22.0) (10.9.0.58)\nRequirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.22.0) (10.2.10.91)\nRequirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.22.0) (11.4.0.1)\nRequirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.22.0) (11.7.4.91)\nRequirement already satisfied: nvidia-nccl-cu11==2.14.3 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.22.0) (2.14.3)\nRequirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.22.0) (11.7.91)\nRequirement already satisfied: triton==2.0.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.22.0) (2.0.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate==0.22.0) (68.0.0)\nRequirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate==0.22.0) (0.40.0)\nRequirement already satisfied: cmake in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.10.0->accelerate==0.22.0) (3.31.2)\nRequirement already satisfied: lit in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.10.0->accelerate==0.22.0) (18.1.8)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.22.0) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.22.0) (1.3.0)\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"!pip install einops==0.6.1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T01:16:32.314609Z","iopub.execute_input":"2024-12-22T01:16:32.314946Z","iopub.status.idle":"2024-12-22T01:16:40.663622Z","shell.execute_reply.started":"2024-12-22T01:16:32.314909Z","shell.execute_reply":"2024-12-22T01:16:40.662669Z"}},"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nRequirement already satisfied: einops==0.6.1 in /opt/conda/lib/python3.10/site-packages (0.6.1)\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"!pip install langchain==0.0.300","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T01:16:40.665402Z","iopub.execute_input":"2024-12-22T01:16:40.665698Z","iopub.status.idle":"2024-12-22T01:16:49.180794Z","shell.execute_reply.started":"2024-12-22T01:16:40.665670Z","shell.execute_reply":"2024-12-22T01:16:49.179631Z"}},"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nRequirement already satisfied: langchain==0.0.300 in /opt/conda/lib/python3.10/site-packages (0.0.300)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (6.0)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (2.0.17)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (3.8.4)\nRequirement already satisfied: anyio<4.0 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (3.7.0)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (4.0.2)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (0.6.0)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (1.33)\nRequirement already satisfied: langsmith<0.1.0,>=0.0.38 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (0.0.92)\nRequirement already satisfied: numexpr<3.0.0,>=2.8.4 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (2.8.5)\nRequirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (1.23.5)\nRequirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (1.10.9)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (2.31.0)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (8.2.2)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.300) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.300) (3.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.300) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.300) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.300) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.300) (1.3.1)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<4.0->langchain==0.0.300) (3.4)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<4.0->langchain==0.0.300) (1.3.0)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio<4.0->langchain==0.0.300) (1.1.1)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.300) (3.20.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.300) (0.9.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain==0.0.300) (2.0)\nRequirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain==0.0.300) (4.6.3)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.0.300) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.0.300) (2023.7.22)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.300) (2.0.2)\nRequirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.300) (21.3)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.300) (1.0.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=17.0->marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.300) (3.0.9)\n","output_type":"stream"}],"execution_count":54},{"cell_type":"code","source":"!pip install xformers==0.0.20","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T01:16:49.184101Z","iopub.execute_input":"2024-12-22T01:16:49.184513Z","iopub.status.idle":"2024-12-22T01:16:57.622492Z","shell.execute_reply.started":"2024-12-22T01:16:49.184474Z","shell.execute_reply":"2024-12-22T01:16:57.621493Z"}},"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nRequirement already satisfied: xformers==0.0.20 in /opt/conda/lib/python3.10/site-packages (0.0.20)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from xformers==0.0.20) (1.23.5)\nRequirement already satisfied: pyre-extensions==0.0.29 in /opt/conda/lib/python3.10/site-packages (from xformers==0.0.20) (0.0.29)\nRequirement already satisfied: torch==2.0.1 in /opt/conda/lib/python3.10/site-packages (from xformers==0.0.20) (2.0.1)\nRequirement already satisfied: typing-inspect in /opt/conda/lib/python3.10/site-packages (from pyre-extensions==0.0.29->xformers==0.0.20) (0.9.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from pyre-extensions==0.0.29->xformers==0.0.20) (4.6.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1->xformers==0.0.20) (3.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1->xformers==0.0.20) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1->xformers==0.0.20) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1->xformers==0.0.20) (3.1.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1->xformers==0.0.20) (11.7.99)\nRequirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1->xformers==0.0.20) (11.7.99)\nRequirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1->xformers==0.0.20) (11.7.101)\nRequirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1->xformers==0.0.20) (8.5.0.96)\nRequirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1->xformers==0.0.20) (11.10.3.66)\nRequirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1->xformers==0.0.20) (10.9.0.58)\nRequirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1->xformers==0.0.20) (10.2.10.91)\nRequirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1->xformers==0.0.20) (11.4.0.1)\nRequirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1->xformers==0.0.20) (11.7.4.91)\nRequirement already satisfied: nvidia-nccl-cu11==2.14.3 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1->xformers==0.0.20) (2.14.3)\nRequirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1->xformers==0.0.20) (11.7.91)\nRequirement already satisfied: triton==2.0.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1->xformers==0.0.20) (2.0.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->xformers==0.0.20) (68.0.0)\nRequirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->xformers==0.0.20) (0.40.0)\nRequirement already satisfied: cmake in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->torch==2.0.1->xformers==0.0.20) (3.31.2)\nRequirement already satisfied: lit in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->torch==2.0.1->xformers==0.0.20) (18.1.8)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.0.1->xformers==0.0.20) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.0.1->xformers==0.0.20) (1.3.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect->pyre-extensions==0.0.29->xformers==0.0.20) (1.0.0)\n","output_type":"stream"}],"execution_count":55},{"cell_type":"code","source":"!pip install bitsandbytes==0.41.1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T01:16:57.623740Z","iopub.execute_input":"2024-12-22T01:16:57.624036Z","iopub.status.idle":"2024-12-22T01:17:05.998823Z","shell.execute_reply.started":"2024-12-22T01:16:57.624009Z","shell.execute_reply":"2024-12-22T01:17:05.997869Z"}},"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nRequirement already satisfied: bitsandbytes==0.41.1 in /opt/conda/lib/python3.10/site-packages (0.41.1)\n","output_type":"stream"}],"execution_count":56},{"cell_type":"code","source":"!pip install sentence_transformers==2.2.2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T01:17:06.000223Z","iopub.execute_input":"2024-12-22T01:17:06.000512Z","iopub.status.idle":"2024-12-22T01:17:14.444529Z","shell.execute_reply.started":"2024-12-22T01:17:06.000486Z","shell.execute_reply":"2024-12-22T01:17:14.443628Z"}},"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nRequirement already satisfied: sentence_transformers==2.2.2 in /opt/conda/lib/python3.10/site-packages (2.2.2)\nRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (4.33.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (4.66.1)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (2.0.1)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (0.15.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (1.23.5)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (1.11.2)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (3.2.4)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (0.1.99)\nRequirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (0.16.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers==2.2.2) (3.12.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers==2.2.2) (2023.9.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers==2.2.2) (2.31.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers==2.2.2) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers==2.2.2) (4.6.3)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers==2.2.2) (21.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (3.1.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (11.7.99)\nRequirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (11.7.99)\nRequirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (11.7.101)\nRequirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (8.5.0.96)\nRequirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (11.10.3.66)\nRequirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (10.9.0.58)\nRequirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (10.2.10.91)\nRequirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (11.4.0.1)\nRequirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (11.7.4.91)\nRequirement already satisfied: nvidia-nccl-cu11==2.14.3 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (2.14.3)\nRequirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (11.7.91)\nRequirement already satisfied: triton==2.0.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (2.0.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->sentence_transformers==2.2.2) (68.0.0)\nRequirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->sentence_transformers==2.2.2) (0.40.0)\nRequirement already satisfied: cmake in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.6.0->sentence_transformers==2.2.2) (3.31.2)\nRequirement already satisfied: lit in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.6.0->sentence_transformers==2.2.2) (18.1.8)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers==2.2.2) (2023.6.3)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers==2.2.2) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers==2.2.2) (0.3.3)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk->sentence_transformers==2.2.2) (1.16.0)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers==2.2.2) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers==2.2.2) (3.1.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence_transformers==2.2.2) (9.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence_transformers==2.2.2) (3.0.9)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence_transformers==2.2.2) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers==2.2.2) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers==2.2.2) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers==2.2.2) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers==2.2.2) (2023.7.22)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence_transformers==2.2.2) (1.3.0)\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"!pip install chromadb==0.4.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T01:17:14.445917Z","iopub.execute_input":"2024-12-22T01:17:14.446251Z","iopub.status.idle":"2024-12-22T01:17:22.951534Z","shell.execute_reply.started":"2024-12-22T01:17:14.446224Z","shell.execute_reply":"2024-12-22T01:17:22.950611Z"}},"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nRequirement already satisfied: chromadb==0.4.0 in /opt/conda/lib/python3.10/site-packages (0.4.0)\nRequirement already satisfied: pandas>=1.3 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.0) (2.0.2)\nRequirement already satisfied: requests>=2.28 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.0) (2.31.0)\nRequirement already satisfied: pydantic<2.0,>=1.9 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.0) (1.10.9)\nRequirement already satisfied: chroma-hnswlib==0.7.1 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.0) (0.7.1)\nRequirement already satisfied: fastapi<0.100.0,>=0.95.2 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.0) (0.98.0)\nRequirement already satisfied: uvicorn[standard]>=0.18.3 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.0) (0.22.0)\nRequirement already satisfied: numpy>=1.21.6 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.0) (1.23.5)\nRequirement already satisfied: posthog>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.0) (3.7.4)\nRequirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.0) (4.6.3)\nRequirement already satisfied: pulsar-client>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.0) (3.5.0)\nRequirement already satisfied: onnxruntime>=1.14.1 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.0) (1.20.1)\nRequirement already satisfied: tokenizers>=0.13.2 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.0) (0.13.3)\nRequirement already satisfied: pypika>=0.48.9 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.0) (0.48.9)\nRequirement already satisfied: tqdm>=4.65.0 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.0) (4.66.1)\nRequirement already satisfied: overrides>=7.3.1 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.0) (7.3.1)\nRequirement already satisfied: importlib-resources in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.0) (5.12.0)\nRequirement already satisfied: starlette<0.28.0,>=0.27.0 in /opt/conda/lib/python3.10/site-packages (from fastapi<0.100.0,>=0.95.2->chromadb==0.4.0) (0.27.0)\nRequirement already satisfied: coloredlogs in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb==0.4.0) (15.0.1)\nRequirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb==0.4.0) (23.5.26)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb==0.4.0) (21.3)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb==0.4.0) (3.20.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb==0.4.0) (1.12)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.3->chromadb==0.4.0) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.3->chromadb==0.4.0) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.3->chromadb==0.4.0) (2023.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb==0.4.0) (1.16.0)\nRequirement already satisfied: monotonic>=1.5 in /opt/conda/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb==0.4.0) (1.6)\nRequirement already satisfied: backoff>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb==0.4.0) (2.2.1)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from pulsar-client>=3.1.0->chromadb==0.4.0) (2023.7.22)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.28->chromadb==0.4.0) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.28->chromadb==0.4.0) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.28->chromadb==0.4.0) (1.26.15)\nRequirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.0) (8.1.7)\nRequirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.0) (0.14.0)\nRequirement already satisfied: httptools>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.0) (0.6.0)\nRequirement already satisfied: python-dotenv>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.0) (1.0.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.0) (6.0)\nRequirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.0) (0.17.0)\nRequirement already satisfied: watchfiles>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.0) (0.20.0)\nRequirement already satisfied: websockets>=10.4 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.0) (11.0.3)\nRequirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/lib/python3.10/site-packages (from starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb==0.4.0) (3.7.0)\nRequirement already satisfied: humanfriendly>=9.1 in /opt/conda/lib/python3.10/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.4.0) (10.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->onnxruntime>=1.14.1->chromadb==0.4.0) (3.0.9)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->onnxruntime>=1.14.1->chromadb==0.4.0) (1.3.0)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb==0.4.0) (1.3.0)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb==0.4.0) (1.1.1)\n","output_type":"stream"}],"execution_count":58},{"cell_type":"code","source":"from torch import cuda, bfloat16\nimport torch\nimport transformers\nfrom transformers import AutoTokenizer\nfrom time import time\n#import chromadb\n#from chromadb.config import Settings\nfrom langchain.llms import HuggingFacePipeline\nfrom langchain.document_loaders import TextLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.chains import RetrievalQA\nfrom langchain.vectorstores import Chroma\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-12-22T01:17:22.953478Z","iopub.execute_input":"2024-12-22T01:17:22.953759Z","iopub.status.idle":"2024-12-22T01:17:22.959322Z","shell.execute_reply.started":"2024-12-22T01:17:22.953733Z","shell.execute_reply":"2024-12-22T01:17:22.958429Z"},"trusted":true},"outputs":[],"execution_count":59},{"cell_type":"markdown","source":"# Initialize model, tokenizer, query pipeline","metadata":{}},{"cell_type":"markdown","source":"Define the model, the device, and the `bitsandbytes` configuration.","metadata":{}},{"cell_type":"code","source":"model_id = '/kaggle/input/llama-2/pytorch/7b-chat-hf/1'\n\ndevice = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n\n# set quantization configuration to load large model with less GPU memory\n# this requires the `bitsandbytes` library\nbnb_config = transformers.BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type='nf4',\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_compute_dtype=bfloat16\n)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-12-22T01:17:22.960386Z","iopub.execute_input":"2024-12-22T01:17:22.960726Z","iopub.status.idle":"2024-12-22T01:17:22.971662Z","shell.execute_reply.started":"2024-12-22T01:17:22.960696Z","shell.execute_reply":"2024-12-22T01:17:22.971012Z"},"trusted":true},"outputs":[],"execution_count":60},{"cell_type":"markdown","source":"Prepare the model and the tokenizer.","metadata":{}},{"cell_type":"code","source":"time_1 = time()\nmodel_config = transformers.AutoConfig.from_pretrained(\n    model_id,\n)\nmodel = transformers.AutoModelForCausalLM.from_pretrained(\n    model_id,\n    trust_remote_code=True,\n    config=model_config,\n    quantization_config=bnb_config,\n    device_map='auto',\n)\ntokenizer = AutoTokenizer.from_pretrained(model_id)\ntime_2 = time()\nprint(f\"Prepare model, tokenizer: {round(time_2-time_1, 3)} sec.\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-12-22T01:17:22.972682Z","iopub.execute_input":"2024-12-22T01:17:22.972982Z","iopub.status.idle":"2024-12-22T01:18:08.372036Z","shell.execute_reply.started":"2024-12-22T01:17:22.972953Z","shell.execute_reply":"2024-12-22T01:18:08.371068Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ea17d61b7cb4345a09e071970b87e0b"}},"metadata":{}},{"name":"stdout","text":"Prepare model, tokenizer: 45.391 sec.\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:367: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":61},{"cell_type":"markdown","source":"Define the query pipeline.","metadata":{}},{"cell_type":"code","source":"time_1 = time()\nquery_pipeline = transformers.pipeline(\n        \"text-generation\",\n        model=model,\n        tokenizer=tokenizer,\n        torch_dtype=torch.float16,\n        device_map=\"auto\",)\ntime_2 = time()\nprint(f\"Prepare pipeline: {round(time_2-time_1, 3)} sec.\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-12-22T01:18:08.373337Z","iopub.execute_input":"2024-12-22T01:18:08.374024Z","iopub.status.idle":"2024-12-22T01:18:08.379941Z","shell.execute_reply.started":"2024-12-22T01:18:08.373986Z","shell.execute_reply":"2024-12-22T01:18:08.378988Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Prepare pipeline: 0.0 sec.\n","output_type":"stream"}],"execution_count":62},{"cell_type":"markdown","source":"We define a function for testing the pipeline.","metadata":{}},{"cell_type":"code","source":"def test_model(tokenizer, pipeline, prompt_to_test):\n    \"\"\"\n    Perform a query\n    print the result\n    Args:\n        tokenizer: the tokenizer\n        pipeline: the pipeline\n        prompt_to_test: the prompt\n    Returns\n        None\n    \"\"\"\n    # adapted from https://huggingface.co/blog/llama2#using-transformers\n    time_1 = time()\n    sequences = pipeline(\n        prompt_to_test,\n        do_sample=True,\n        top_k=10,\n        num_return_sequences=1,\n        eos_token_id=tokenizer.eos_token_id,\n        max_length=200,)\n    time_2 = time()\n    print(f\"Test inference: {round(time_2-time_1, 3)} sec.\")\n    for seq in sequences:\n        print(f\"Result: {seq['generated_text']}\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-12-22T01:18:08.380927Z","iopub.execute_input":"2024-12-22T01:18:08.381217Z","iopub.status.idle":"2024-12-22T01:18:08.392048Z","shell.execute_reply.started":"2024-12-22T01:18:08.381195Z","shell.execute_reply":"2024-12-22T01:18:08.391460Z"},"trusted":true},"outputs":[],"execution_count":63},{"cell_type":"markdown","source":"## Test the query pipeline\n\nWe test the pipeline with a query about the meaning of State of the Union (SOTU).","metadata":{}},{"cell_type":"code","source":"test_model(tokenizer,\n           query_pipeline,\n           \"Please explain what are the changes which occurred during the time period 1600-1699 related to Measurement and theory. Keep it in 100 words.\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-12-22T01:18:08.395097Z","iopub.execute_input":"2024-12-22T01:18:08.395386Z","iopub.status.idle":"2024-12-22T01:18:20.714024Z","shell.execute_reply.started":"2024-12-22T01:18:08.395364Z","shell.execute_reply":"2024-12-22T01:18:20.713196Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Test inference: 12.308 sec.\nResult: Please explain what are the changes which occurred during the time period 1600-1699 related to Measurement and theory. Keep it in 100 words.\n\nThe period 1600-1699 witnessed significant advancements in measurement and theoretical understanding. In 1619, the British Parliament passed the Weights and Measures Act, which standardized units of measurement and established the Royal Standards. Sir Isaac Newton's groundbreaking work in physics, particularly his laws of motion and universal gravitation, refined the understanding of measurement and its principles. The development of the calculus by Sir Isaac Newton and Gottfried Wilhelm Leibniz revolutionized mathematical measurements, enabling the calculation of more precise distances, areas, and volumes. The period also saw the introduction of new scientific instruments, including the telescope and microscope, which aided in precise measurements of celestial and microscopic phen\n","output_type":"stream"}],"execution_count":64},{"cell_type":"markdown","source":"# Retrieval Augmented Generation","metadata":{}},{"cell_type":"markdown","source":"## Check the model with a HuggingFace pipeline\n\n\nWe check the model with a HF pipeline, using a query about the meaning of State of the Union (SOTU).","metadata":{"execution":{"iopub.status.busy":"2023-09-23T19:22:16.433666Z","iopub.execute_input":"2023-09-23T19:22:16.434937Z","iopub.status.idle":"2023-09-23T19:22:16.440864Z","shell.execute_reply.started":"2023-09-23T19:22:16.434891Z","shell.execute_reply":"2023-09-23T19:22:16.439217Z"}}},{"cell_type":"code","source":"llm = HuggingFacePipeline(pipeline=query_pipeline)\n# checking again that everything is working fine\nllm(prompt=\"Please explain what are the changes which occurred during the time period  1800-1850 related to Beginnings of modern graphics. Keep it in 100 words.\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-12-22T01:18:20.715272Z","iopub.execute_input":"2024-12-22T01:18:20.715625Z","iopub.status.idle":"2024-12-22T01:18:31.320144Z","shell.execute_reply.started":"2024-12-22T01:18:20.715585Z","shell.execute_reply":"2024-12-22T01:18:31.319182Z"},"trusted":true},"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"' \\n\\nDuring the time period of 1800-1850, modern graphics began to take shape with the advent of new technologies and artistic movements. The invention of lithography in 1796 allowed for mass production of printed images, while the development of photography in the 1830s revolutionized the field of graphic design. Additionally, the rise of Romanticism and the Arts and Crafts movement emphasized the importance of handmade craftsmanship and the use of traditional techniques in graphic design. These changes laid the groundwork for the modern graphic design industry as we know it today.'"},"metadata":{}}],"execution_count":65},{"cell_type":"markdown","source":"## Ingestion of data using Text loder\n\nWe will ingest the newest presidential address, from Jan 2023.","metadata":{}},{"cell_type":"code","source":"loader = TextLoader(\"/kaggle/input/dv-research-paper-summary/dv_research_paper_summary.txt\",\n                    encoding=\"utf8\")\ndocuments = loader.load()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-12-22T01:18:31.321385Z","iopub.execute_input":"2024-12-22T01:18:31.321633Z","iopub.status.idle":"2024-12-22T01:18:31.328206Z","shell.execute_reply.started":"2024-12-22T01:18:31.321611Z","shell.execute_reply":"2024-12-22T01:18:31.327167Z"},"trusted":true},"outputs":[],"execution_count":66},{"cell_type":"markdown","source":"## Split data in chunks\n\nWe split data in chunks using a recursive character text splitter.","metadata":{}},{"cell_type":"code","source":"text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\nall_splits = text_splitter.split_documents(documents)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-12-22T01:18:31.329448Z","iopub.execute_input":"2024-12-22T01:18:31.330314Z","iopub.status.idle":"2024-12-22T01:18:31.338966Z","shell.execute_reply.started":"2024-12-22T01:18:31.330288Z","shell.execute_reply":"2024-12-22T01:18:31.338309Z"},"trusted":true},"outputs":[],"execution_count":67},{"cell_type":"markdown","source":"## Creating Embeddings and Storing in Vector Store","metadata":{}},{"cell_type":"markdown","source":"Create the embeddings using Sentence Transformer and HuggingFace embeddings.","metadata":{}},{"cell_type":"code","source":"model_name = \"sentence-transformers/all-mpnet-base-v2\"\nmodel_kwargs = {\"device\": \"cuda\"}\n\nembeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-12-22T01:18:31.339971Z","iopub.execute_input":"2024-12-22T01:18:31.340273Z","iopub.status.idle":"2024-12-22T01:18:32.448396Z","shell.execute_reply.started":"2024-12-22T01:18:31.340250Z","shell.execute_reply":"2024-12-22T01:18:32.447670Z"},"trusted":true},"outputs":[],"execution_count":68},{"cell_type":"markdown","source":"Initialize ChromaDB with the document splits, the embeddings defined previously and with the option to persist it locally.","metadata":{}},{"cell_type":"code","source":"vectordb = Chroma.from_documents(documents=all_splits, embedding=embeddings, persist_directory=\"chroma_db\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-12-22T01:18:32.449274Z","iopub.execute_input":"2024-12-22T01:18:32.449502Z","iopub.status.idle":"2024-12-22T01:18:32.781403Z","shell.execute_reply.started":"2024-12-22T01:18:32.449482Z","shell.execute_reply":"2024-12-22T01:18:32.780679Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c2fab2b256c4ee884bee7a5d8a0ff34"}},"metadata":{}}],"execution_count":69},{"cell_type":"markdown","source":"## Initialize chain","metadata":{}},{"cell_type":"code","source":"retriever = vectordb.as_retriever()\n\nqa = RetrievalQA.from_chain_type(\n    llm=llm, \n    chain_type=\"stuff\", \n    retriever=retriever, \n    verbose=True\n)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-12-22T01:18:32.782298Z","iopub.execute_input":"2024-12-22T01:18:32.782552Z","iopub.status.idle":"2024-12-22T01:18:32.796493Z","shell.execute_reply.started":"2024-12-22T01:18:32.782530Z","shell.execute_reply":"2024-12-22T01:18:32.795640Z"},"trusted":true},"outputs":[],"execution_count":70},{"cell_type":"markdown","source":"## Test the Retrieval-Augmented Generation \n\n\nWe define a test function, that will run the query and time it.","metadata":{}},{"cell_type":"code","source":"def test_rag(qa, query):\n    print(f\"Query: {query}\\n\")\n    time_1 = time()\n    result = qa.run(query)\n    time_2 = time()\n    print(f\"Inference time: {round(time_2-time_1, 3)} sec.\")\n    print(\"\\nResult: \", result)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-12-22T01:18:32.797778Z","iopub.execute_input":"2024-12-22T01:18:32.798107Z","iopub.status.idle":"2024-12-22T01:18:32.806085Z","shell.execute_reply.started":"2024-12-22T01:18:32.798078Z","shell.execute_reply":"2024-12-22T01:18:32.805190Z"},"trusted":true},"outputs":[],"execution_count":71},{"cell_type":"markdown","source":"Let's check few queries.","metadata":{}},{"cell_type":"code","source":"query = \"Please explain what are the changes which occurred during the time period 18501900 related to The Golden Age of statistical graphics. Keep it under 200 words.\"\n\ntest_rag(qa, query)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-12-22T01:18:32.807246Z","iopub.execute_input":"2024-12-22T01:18:32.807491Z","iopub.status.idle":"2024-12-22T01:18:49.550411Z","shell.execute_reply.started":"2024-12-22T01:18:32.807469Z","shell.execute_reply":"2024-12-22T01:18:49.549490Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Query: Please explain what are the changes which occurred during the time period 18501900 related to The Golden Age of statistical graphics. Keep it under 200 words.\n\n\n\n\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16dd056e0d004e73ac52f06208596a3b"}},"metadata":{}},{"name":"stdout","text":"\n\u001b[1m> Finished chain.\u001b[0m\nInference time: 16.731 sec.\n\nResult:   During the time period of 18501900, there were significant changes in the field of statistical graphics, which became known as the Golden Age. Emile Cheysson's work exemplified this era's creativity, combining various graphical techniques to present comprehensive insights into national data. The integration of multiple variables and creative layouts characterized this period, setting benchmarks for modern visualization. Despite cultural differences in data visualization, innovations in thematic mapping and statistical representation continued to spread globally. However, this period also saw a decline in graphical innovation, with statistical analysis becoming dominated by numerical precision. Visualizations were seen as secondary to tables and equations, but graphical methods entered mainstream education and government use, appearing in textbooks and public reports. Notable scientific breakthroughs relied on visualization, demonstrating how graphs could reveal underlying structures in complex data.\n","output_type":"stream"}],"execution_count":72},{"cell_type":"code","source":"query = \"What are the major impacts of effective data visualization? Summarize. Keep it under 200 words.\"\ntest_rag(qa, query)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-12-22T01:18:49.551622Z","iopub.execute_input":"2024-12-22T01:18:49.551888Z","iopub.status.idle":"2024-12-22T01:19:00.525420Z","shell.execute_reply.started":"2024-12-22T01:18:49.551860Z","shell.execute_reply":"2024-12-22T01:19:00.524488Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Query: What are the major impacts of effective data visualization? Summarize. Keep it under 200 words.\n\n\n\n\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27599697e4874cc9a31ef8d2fe76b9a6"}},"metadata":{}},{"name":"stdout","text":"\n\u001b[1m> Finished chain.\u001b[0m\nInference time: 10.97 sec.\n\nResult:   Effective data visualization can have significant impacts on decision-making, communication, and learning. It can help decision-makers identify patterns and trends, make more informed decisions, and communicate complex data insights to stakeholders. In education, visualizing data can enhance student engagement, understanding, and retention of information. Additionally, visualization can facilitate collaboration and idea exchange among researchers, fostering new insights and discoveries. Overall, effective data visualization can lead to better decision-making, more effective communication, and improved learning outcomes.\n","output_type":"stream"}],"execution_count":73},{"cell_type":"markdown","source":"## Document sources\n\nLet's check the documents sources, for the last query run.","metadata":{}},{"cell_type":"code","source":"docs = vectordb.similarity_search(query)\nprint(f\"Query: {query}\")\nprint(f\"Retrieved documents: {len(docs)}\")\nfor doc in docs:\n    doc_details = doc.to_json()['kwargs']\n    print(\"Source: \", doc_details['metadata']['source'])\n    print(\"Text: \", doc_details['page_content'], \"\\n\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-12-22T01:19:00.526388Z","iopub.execute_input":"2024-12-22T01:19:00.526679Z","iopub.status.idle":"2024-12-22T01:19:00.563607Z","shell.execute_reply.started":"2024-12-22T01:19:00.526654Z","shell.execute_reply":"2024-12-22T01:19:00.562753Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abd2e36ae0e24bc29242f9ae7e375bb6"}},"metadata":{}},{"name":"stdout","text":"Query: What are the major impacts of effective data visualization? Summarize. Keep it under 200 words.\nRetrieved documents: 4\nSource:  /kaggle/input/dv-research-paper-summary/dv_research_paper_summary.txt\nText:  intelligence, and virtual reality to create dynamic, interactive visualizations. These tools make complex data more accessible, fostering better decision-making and communication. Despite its progress, the field faces challenges in balancing aesthetics and accuracy. Misleading visualizations can distort information, emphasizing the need for ethical practices. Nonetheless, the history of data visualization underscores its potential to transform how we understand and interact with data. Contemporary tools build upon centuries of innovation, blending artistry and analytical rigor to unlock new possibilities for understanding the world. \n\nSource:  /kaggle/input/dv-research-paper-summary/dv_research_paper_summary.txt\nText:  intelligence, and virtual reality to create dynamic, interactive visualizations. These tools make complex data more accessible, fostering better decision-making and communication. Despite its progress, the field faces challenges in balancing aesthetics and accuracy. Misleading visualizations can distort information, emphasizing the need for ethical practices. Nonetheless, the history of data visualization underscores its potential to transform how we understand and interact with data. Contemporary tools build upon centuries of innovation, blending artistry and analytical rigor to unlock new possibilities for understanding the world. \n\nSource:  /kaggle/input/dv-research-paper-summary/dv_research_paper_summary.txt\nText:  John Tukeys \"Exploratory Data Analysis\" (EDA) emphasized the importance of visual tools like box plots and stem-and-leaf diagrams for exploring data patterns. Tukeys philosophy highlighted the role of graphs in uncovering insights that traditional statistical models might overlook. Advancements in computing enabled the creation of complex visualizations. Geographic Information Systems (GIS) and early computer-generated graphs allowed researchers to handle large datasets more effectively. This period also saw the emergence of interactive visual tools, setting the stage for modern data visualization practices. Innovations in three-dimensional visualization and dynamic graphing expanded the possibilities for presenting and analyzing data. Modern Developments and Applications Today, data visualization is a critical tool across various domains, including science, business, and education. Modern techniques leverage advanced technologies like machine learning, artificial intelligence, and \n\nSource:  /kaggle/input/dv-research-paper-summary/dv_research_paper_summary.txt\nText:  John Tukeys \"Exploratory Data Analysis\" (EDA) emphasized the importance of visual tools like box plots and stem-and-leaf diagrams for exploring data patterns. Tukeys philosophy highlighted the role of graphs in uncovering insights that traditional statistical models might overlook. Advancements in computing enabled the creation of complex visualizations. Geographic Information Systems (GIS) and early computer-generated graphs allowed researchers to handle large datasets more effectively. This period also saw the emergence of interactive visual tools, setting the stage for modern data visualization practices. Innovations in three-dimensional visualization and dynamic graphing expanded the possibilities for presenting and analyzing data. Modern Developments and Applications Today, data visualization is a critical tool across various domains, including science, business, and education. Modern techniques leverage advanced technologies like machine learning, artificial intelligence, and \n\n","output_type":"stream"}],"execution_count":74},{"cell_type":"markdown","source":"# Conclusions\n\n\nWe used Langchain, ChromaDB and Llama 2 as a LLM to build a Retrieval Augmented Generation solution. For testing, we were using my Data visualization class research paper read. \n","metadata":{}},{"cell_type":"markdown","source":"# References  \n\n[1] Murtuza Kazmi, Using LLaMA 2.0, FAISS and LangChain for Question-Answering on Your Own Data, https://medium.com/@murtuza753/using-llama-2-0-faiss-and-langchain-for-question-answering-on-your-own-data-682241488476  \n\n[2] Patrick Lewis, Ethan Perez, et. al., Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks, https://browse.arxiv.org/pdf/2005.11401.pdf \n\n[3] Minhajul Hoque, Retrieval Augmented Generation: Grounding AI Responses in Factual Data, https://medium.com/@minh.hoque/retrieval-augmented-generation-grounding-ai-responses-in-factual-data-b7855c059322  \n\n[4] Fangrui Liu\t, Discover the Performance Gain with Retrieval Augmented Generation, https://thenewstack.io/discover-the-performance-gain-with-retrieval-augmented-generation/\n\n[5] Andrew, How to use Retrieval-Augmented Generation (RAG) with Llama 2, https://agi-sphere.com/retrieval-augmented-generation-llama2/   \n\n[6] Yogendra Sisodia, Retrieval Augmented Generation Using Llama2 And Falcon, https://medium.com/@scholarly360/retrieval-augmented-generation-using-llama2-and-falcon-ed26c7b14670   \n\n","metadata":{}}]}